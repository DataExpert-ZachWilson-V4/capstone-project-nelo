FROM apache/airflow:2.9.1

USER root

RUN apt-get update \
    && apt-get install -y --no-install-recommends \
         python3-pip \
         openjdk-17-jre-headless \
         wget \
         curl \
         gcc \
         python3-dev \
         libffi-dev \
         libpq-dev \
         procps \
         chrony \
    && apt-get autoremove -yqq --purge \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

ENV SPARK_VERSION=3.5.1
ENV HADOOP_VERSION=3
ENV SPARK_HOME=/opt/spark
ENV ICEBERG_VERSION=1.5.2

RUN wget -O /tmp/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz https://dlcdn.apache.org/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz \
    && tar xzf /tmp/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz -C /opt \
    && ln -s "/opt/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION" $SPARK_HOME \
    && rm /tmp/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz

RUN wget -O $SPARK_HOME/jars/iceberg-spark-runtime-$SPARK_VERSION.jar "https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-3.3_2.13/$ICEBERG_VERSION/iceberg-spark-runtime-3.3_2.13-$ICEBERG_VERSION.jar"

RUN wget -O $SPARK_HOME/jars/spark-sql-kafka-0-10_2.13-3.5.1.jar "https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.13/3.5.1/spark-sql-kafka-0-10_2.13-3.5.1.jar"

ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
ENV PATH=$PATH:$JAVA_HOME/bin:$SPARK_HOME/bin

WORKDIR /opt/airflow

COPY ./dbt/dbt_project.yml /opt/airflow/dbt/dbt_project.yml
COPY ./dbt/profiles.yml /opt/airflow/dbt/profiles.yml
COPY ./dbt/models/ /opt/airflow/dbt/models/
COPY ./dbt/tests/ /opt/airflow/dbt/tests/
COPY ./dags /opt/airflow/dags/
COPY ./Spark_streams /opt/airflow/Spark_streams/
COPY ./Qdrant_streams /opt/airflow/Qdrant_streams/
COPY ./Future_predictions_streams /opt/airflow/Future_predictions_streams
COPY ./main.py /opt/airflow/main.py 
COPY ./app/start_producers.py /opt/airflow/start_producers.py
COPY ./app/start_consumers.py /opt/airflow/start_consumers.py
COPY ./app /app

RUN chmod +x /opt/airflow/start_producers.py
RUN chmod +x /opt/airflow/start_consumers.py

# Start chrony for time synchronization
RUN service chrony start

USER airflow

RUN pip install --no-cache-dir \
    "apache-airflow==2.9.1" \
    apache-airflow-providers-apache-spark==2.1.3 \
    kafka-python-ng \
    six \
    flower \
    qdrant-client \
    xgboost \
    scikit-learn \
    bayesian-optimization \
    pandas \
    azure-storage-blob \
    python-dotenv \
    tenacity \
    dbt-core \
    dbt-spark[PyHive] \
    psycopg2 \
    psycopg2-binary
